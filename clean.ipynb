{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f8c36297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# database imports\n",
    "import re as re\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "#from pymongo import MongoClient # FIX: determine which packages to rmv\n",
    "import numpy as np\n",
    "\n",
    "# tokenization imports\n",
    "#from nltk.corpus import stopwords\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbabf221",
   "metadata": {},
   "source": [
    "### Precleaning Notes\n",
    "- some bullet points don't separate words, so I will need to use regex to find key terms like 'Python' and 'Machine Learning.'\n",
    "- skills and roles are mentioned multiple times throughout a description, so I will need to find a way to limit the skill count increase to one per page.\n",
    "- remote positions will mostly be empty, but this does not imply on-site. I should try to check the description as well.\n",
    "- df.title=df.title.str.lower()\n",
    "- df.title=df.title.str.lstrip()\n",
    "- df.title=df.title.str.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53fe5b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('linkedin_jobs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ca4820",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ff1a7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>post_date</th>\n",
       "      <th>num_applicants</th>\n",
       "      <th>full_time</th>\n",
       "      <th>size</th>\n",
       "      <th>description</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Frontiers</td>\n",
       "      <td>Spain</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>105 applicants</td>\n",
       "      <td>level</td>\n",
       "      <td>1,001-5,000 employees · Book and Periodical Pu...</td>\n",
       "      <td>About the job\\n          \\n\\n \\nWe are on a mi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst (f/m)</td>\n",
       "      <td>Axpo Group</td>\n",
       "      <td>Madrid, Community of Madrid, Spain</td>\n",
       "      <td>14 hours ago</td>\n",
       "      <td>1 applicant</td>\n",
       "      <td>Associate</td>\n",
       "      <td>5,001-10,000 employees · Utilities</td>\n",
       "      <td>About the job\\n          \\n\\n \\n              ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Architect</td>\n",
       "      <td>Adobe</td>\n",
       "      <td>Barcelona, Catalonia, Spain</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>56 applicants</td>\n",
       "      <td>level</td>\n",
       "      <td>10,001+ employees · Software Development</td>\n",
       "      <td>About the job\\n          \\n\\n \\nOur Company\\n\\...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data scientist</td>\n",
       "      <td>HP</td>\n",
       "      <td>Sant Cugat del Vallès, Catalonia, Spain</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>30 applicants</td>\n",
       "      <td>level</td>\n",
       "      <td>10,001+ employees · IT Services and IT Consulting</td>\n",
       "      <td>About the job\\n          \\n\\n \\n              ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Solution Architect</td>\n",
       "      <td>Bumble</td>\n",
       "      <td>Barcelona, Catalonia, Spain</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>25 applicants</td>\n",
       "      <td>Associate</td>\n",
       "      <td>501-1,000 employees · Technology, Information ...</td>\n",
       "      <td>About the job\\n          \\n\\n \\nWe strongly en...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Principal Marketing Data Scientist</td>\n",
       "      <td>Bandai Namco Mobile</td>\n",
       "      <td>Barcelona, Catalonia, Spain</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>level</td>\n",
       "      <td>11-50 employees · Computer Games</td>\n",
       "      <td>About the job\\n          \\n\\n \\nPAC-MAN to Tek...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Data Platform Engineer (f/m/d)</td>\n",
       "      <td>Axpo Group</td>\n",
       "      <td>Madrid, Community of Madrid, Spain</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Associate</td>\n",
       "      <td>5,001-10,000 employees · Utilities</td>\n",
       "      <td>About the job\\n          \\n\\n \\n              ...</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Global Integration Services Architect</td>\n",
       "      <td>ADP</td>\n",
       "      <td>Barcelona, Catalonia, Spain</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contract</td>\n",
       "      <td>10,001+ employees · Human Resources Services</td>\n",
       "      <td>About the job\\n          \\n\\n \\nGlobal Integra...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Data scientist, Engineer, Physicist, Computer ...</td>\n",
       "      <td>German Aerospace Center (DLR)</td>\n",
       "      <td>Almería, Andalusia, Spain</td>\n",
       "      <td>1 month ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>level</td>\n",
       "      <td>5,001-10,000 employees · Research Services</td>\n",
       "      <td>About the job\\n          \\n\\n \\n              ...</td>\n",
       "      <td>Part-time · Entry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Data Analysis Specialist</td>\n",
       "      <td>PPG</td>\n",
       "      <td>Barcelona, Catalonia, Spain</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>10,001+ employees · Chemical Manufacturing</td>\n",
       "      <td>About the job\\n          \\n\\n \\n              ...</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                                      Data Scientist   \n",
       "1                           Senior Data Analyst (f/m)   \n",
       "2                                      Data Architect   \n",
       "3                                      Data scientist   \n",
       "4                             Data Solution Architect   \n",
       "..                                                ...   \n",
       "69                 Principal Marketing Data Scientist   \n",
       "70                     Data Platform Engineer (f/m/d)   \n",
       "71              Global Integration Services Architect   \n",
       "72  Data scientist, Engineer, Physicist, Computer ...   \n",
       "73                           Data Analysis Specialist   \n",
       "\n",
       "                          company                                 location  \\\n",
       "0                       Frontiers                                    Spain   \n",
       "1                      Axpo Group       Madrid, Community of Madrid, Spain   \n",
       "2                           Adobe              Barcelona, Catalonia, Spain   \n",
       "3                              HP  Sant Cugat del Vallès, Catalonia, Spain   \n",
       "4                          Bumble              Barcelona, Catalonia, Spain   \n",
       "..                            ...                                      ...   \n",
       "69            Bandai Namco Mobile              Barcelona, Catalonia, Spain   \n",
       "70                     Axpo Group       Madrid, Community of Madrid, Spain   \n",
       "71                            ADP              Barcelona, Catalonia, Spain   \n",
       "72  German Aerospace Center (DLR)                Almería, Andalusia, Spain   \n",
       "73                            PPG              Barcelona, Catalonia, Spain   \n",
       "\n",
       "       post_date  num_applicants  full_time  \\\n",
       "0     1 week ago  105 applicants      level   \n",
       "1   14 hours ago     1 applicant  Associate   \n",
       "2     1 week ago   56 applicants      level   \n",
       "3     1 week ago   30 applicants      level   \n",
       "4     3 days ago   25 applicants  Associate   \n",
       "..           ...             ...        ...   \n",
       "69   2 weeks ago             NaN      level   \n",
       "70     1 day ago             NaN  Associate   \n",
       "71     1 day ago             NaN   Contract   \n",
       "72   1 month ago             NaN      level   \n",
       "73    3 days ago             NaN  Full-time   \n",
       "\n",
       "                                                 size  \\\n",
       "0   1,001-5,000 employees · Book and Periodical Pu...   \n",
       "1                  5,001-10,000 employees · Utilities   \n",
       "2            10,001+ employees · Software Development   \n",
       "3   10,001+ employees · IT Services and IT Consulting   \n",
       "4   501-1,000 employees · Technology, Information ...   \n",
       "..                                                ...   \n",
       "69                   11-50 employees · Computer Games   \n",
       "70                 5,001-10,000 employees · Utilities   \n",
       "71       10,001+ employees · Human Resources Services   \n",
       "72         5,001-10,000 employees · Research Services   \n",
       "73         10,001+ employees · Chemical Manufacturing   \n",
       "\n",
       "                                          description             salary  \n",
       "0   About the job\\n          \\n\\n \\nWe are on a mi...                NaN  \n",
       "1   About the job\\n          \\n\\n \\n              ...                NaN  \n",
       "2   About the job\\n          \\n\\n \\nOur Company\\n\\...                NaN  \n",
       "3   About the job\\n          \\n\\n \\n              ...                NaN  \n",
       "4   About the job\\n          \\n\\n \\nWe strongly en...                NaN  \n",
       "..                                                ...                ...  \n",
       "69  About the job\\n          \\n\\n \\nPAC-MAN to Tek...                NaN  \n",
       "70  About the job\\n          \\n\\n \\n              ...          Full-time  \n",
       "71  About the job\\n          \\n\\n \\nGlobal Integra...                NaN  \n",
       "72  About the job\\n          \\n\\n \\n              ...  Part-time · Entry  \n",
       "73  About the job\\n          \\n\\n \\n              ...          Full-time  \n",
       "\n",
       "[74 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ccbfec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title              0\n",
       "company            0\n",
       "location           0\n",
       "post_date          1\n",
       "num_applicants    51\n",
       "full_time          0\n",
       "size               0\n",
       "description        0\n",
       "salary            53\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace null values\n",
    "df.isnull().sum()\n",
    "#df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5bab67",
   "metadata": {},
   "source": [
    "**Number of applicants** would be nice to compare against the job's **post date** but so many missing values may skew our data. We will evaluate what we have anyway, knowing this.\n",
    "\n",
    "**Salary** was difficult to find, but it can be merged with Glassdoor later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83f1d766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data Analyst                                                                  4\n",
       "Data Scientist, Commercial Systems                                            3\n",
       "Senior Data Scientist                                                         3\n",
       "Data Analysis Specialist                                                      3\n",
       "Data Architect                                                                2\n",
       "                                                                             ..\n",
       "Principal Data Scientist                                                      1\n",
       "DevOps Engineer (E3)                                                          1\n",
       "Turkish Seller Onboarding, RCCS                                               1\n",
       "Python Developer Remote                                                       1\n",
       "Data scientist, Engineer, Physicist, Computer scientist or similar (f/m/x)    1\n",
       "Name: title, Length: 63, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# given the inaccuracy and missing value counts of previous data sets, check columns like salary info...\n",
    "# and all the rest while we're at it\n",
    "df.title.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea4e888",
   "metadata": {},
   "source": [
    "### Title Column Tasks\n",
    "- Use regex to group roles together into new \"role column\". \n",
    "- There are many jobs here that do not match data science, which should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d88aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX: import data job list from scrape file!\n",
    "\n",
    "def roles(list_):\n",
    "    new_list = []\n",
    "    for item in list_:\n",
    "        if 'data analyst' in item: # FIX: lower/uppercase doesn't matter\n",
    "            new_list.append('Data Analyst')\n",
    "        elif ...\n",
    "        \n",
    "    return new_list\n",
    "\n",
    "df.insert(0, role, roles(df.title)) # FIX: need to self-reference? df = ...\n",
    "\n",
    "def rm_unrelated_jobs(df):\n",
    "    for item in df:\n",
    "        if df.title not in job_list:\n",
    "            item.drop() # FIX\n",
    "    return df\n",
    "\n",
    "df = (rm_unrelated_jobs(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2952f8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Barcelona, Catalonia, Spain                        39\n",
       "Madrid, Community of Madrid, Spain                 12\n",
       "Spain                                               5\n",
       "Sant Cugat del Vallès, Catalonia, Spain             3\n",
       "Greater Barcelona Metropolitan Area                 3\n",
       "Almería, Andalusia, Spain                           2\n",
       "Alcorcón, Community of Madrid, Spain                1\n",
       "Seville, Andalusia, Spain                           1\n",
       "Málaga, Andalusia, Spain                            1\n",
       "Valencia, Valencian Community, Spain                1\n",
       "Alicante, Valencian Community, Spain                1\n",
       "Palma, Balearic Islands, Spain                      1\n",
       "Zaragoza, Aragon, Spain                             1\n",
       "European Economic Area                              1\n",
       "Pamplona, Chartered Community of Navarre, Spain     1\n",
       "Greater Madrid Metropolitan Area                    1\n",
       "Name: location, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cdcee55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level         38\n",
       "Associate     18\n",
       "Full-time     14\n",
       "Internship     1\n",
       "Executive      1\n",
       "Platforms      1\n",
       "Contract       1\n",
       "Name: full_time, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.contract_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad724011",
   "metadata": {},
   "source": [
    "### Full Time Column Task\n",
    "- Erroneous entries like 'platforms' should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a5f5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_unrelated_platforms(df):\n",
    "    contract_types = ['Associate', 'Full-time', 'Internship', 'Executive', 'Contract']\n",
    "    for item in df:\n",
    "        if df.contract_type not in contract_types:\n",
    "            item.drop() # FIX\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8792089e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.int64' object has no attribute 'value_counts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_counts\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.int64' object has no attribute 'value_counts'"
     ]
    }
   ],
   "source": [
    "df.company_size.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59db6d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Full-time                 8\n",
       "Full-time · Entry         7\n",
       "Full-time · Mid-Senior    3\n",
       "Part-time · Entry         3\n",
       "Name: salary, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.salary.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa79fdb",
   "metadata": {},
   "source": [
    "### Salary Column Task\n",
    "- As I was not able to grab the correct salary information from LinkedIn, and salary data on LinekdIn is so sparse anyway, I will drop this column and scrape Glassdoor for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d59b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['salary'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3cc38e",
   "metadata": {},
   "source": [
    "# Cleaning & Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e16f63",
   "metadata": {},
   "source": [
    "As **job description** is the most variable and complex column to grab data from, we will have to perform several actions on it and store the new data in a new column, labeled **'skills.'** Unfortunately, bullet points were not captured from the descriptions so some words are joined with the last word of the previous bullet. We will need to add a space before each capital letter just to solve this issue, and the remove any double-spaces.\n",
    "- basic cleaning (strip, replace line breaks, etc)\n",
    "- add a space before each capital letter, then remove any double-spaces\n",
    "- filter out stop words\n",
    "- tokenize all words\n",
    "- print description list's most popular terms and save useful words into new column, 'skills'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae0793d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About the job\n",
      "          \n",
      "\n",
      " \n",
      "We are on a mission to make science open so everyone can live healthy lives on a healthy planet\n",
      "\n",
      "Who We Are\n",
      "\n",
      "Frontiers is an award-winning open science platform and leading open access scholarly publisher.\n",
      "\n",
      "We are one of the largest and most cited publishers globally. To date, our 200,000 freely available research articles have received more than 1 billion views and downloads and 2 million citations. Our journals span science, health, humanities and social sciences, engineering, and sustainability. And we continue to expand into new academic disciplines so more researchers can publish open access.\n",
      "\n",
      "Be part of the publishing revolution and help us transform the way research is published, evaluated, and communicated to the world.\n",
      "\n",
      "Job Role\n",
      "\n",
      "We are looking for a Data Scientist to work on production-ready Artificial Intelligence (AI) to support our industry-leading AI publishing platform. You will focus on recommender systems and work with Product Owners, ML Engineers and Data Engineers to develop solutions that will evolve our cutting edge AI Review Assistant (AIRA).\n",
      "\n",
      "Key Responsibilities\n",
      "Development, optimization and evaluation of ML models and algorithmsTechnological review of data science solutions and communication to non-technical stakeholdersProactive identification of opportunities for potential AI products within FrontiersEffective collaboration with product managers, ML engineers, software and data engineers design scalable state of the art ML models\n",
      "\n",
      "Key Requirements\n",
      "Solid experience of working as a Data ScientistFamiliarity with: Regression techniques, ensemble methods, decision trees, clustering techniquesProficiency in PythonWillingness to share and adopt best work practices on a common codebase (Python packaging, version control, pull requests, testing, continuous integration)Experience with SQL and big data platforms (e.g. Spark, Azure Databricks)Familiarity with problem specification formulation and translation to functional/non-functional requirements for ML model buildingFamiliarity with identifying under/over fitting in ML models and bias/variance trade-offsFamiliarity with algorithm selection giving consideration to accuracy, training time, model complexity, parameters' and features' managementCandidates are encouraged to share portfolio of recommender systems projects.\n",
      "\n",
      "Benefits\n",
      "\n",
      "With more than 50 nationalities represented in our global team, you will work regularly with teammates in other countries, and with our community of researchers, editors, and authors from around the globe.\n",
      "\n",
      "Our mission to create solutions for healthy lives also extends to the working environment we provide for our employees.\n",
      "\n",
      "This includes:\n",
      "\n",
      "100% remote working\n",
      "\n",
      "Employees now have the flexibility to choose where they want to work, with remote working available on a part- or full-time basis.\n",
      "\n",
      "Learning and development\n",
      "\n",
      "All employees have access to LinkedIn Learning (and Pluralsight for our technology team), an annual personal learning budget, and dedicated L&D time.\n",
      "\n",
      "Wellbeing\n",
      "\n",
      "We offer free online yoga classes, an employee assistance plan, access to the Headspace app, and four wellbeing days on top of your annual leave allowance.\n",
      "\n",
      "Volunteering opportunities\n",
      "\n",
      "Employees can dedicate three days each year to volunteer for a personal cause or through our volunteering partner platform, Alaya.\n",
      "\n",
      "Frontiers actively embraces diversity and is a safe and welcoming workplace. Recruitment is free from discrimination – including based on race, national or ethnic origin, age, religion, disability, sex, gender identity or sexual orientation. With over 600 employees from more than 50 different nations, our diversity creates vibrant teams and constantly challenges us to appreciate multiple perspectives.\n"
     ]
    }
   ],
   "source": [
    "print(df.description[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2816fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_specials(desc):\n",
    "    \"\"\" remove all special characters from text \"\"\"\n",
    "    for char in ['\\n','\\\\','`','*','_','{','}','[',']','(',')','>','#','+','-',',','.','!','$','\\'']:\n",
    "        if char in desc:\n",
    "            desc = desc.replace(char, \"\")\n",
    "    return desc\n",
    "\n",
    "\n",
    "\n",
    "def clean_text(desc_list):\n",
    "    \"\"\" basic text cleaning before tokenization \"\"\"\n",
    "    clean_desc_list = []\n",
    "    for desc in desc_list:\n",
    "        desc = desc.strip()\n",
    "        desc = rm_specials(desc) # remove special characters\n",
    "        desc = re.sub(r\"(\\w)([A-Z])\", r\"\\1 \\2\", desc) # add a space before each capital letter to ensure bullet pointed lists are not joined together\n",
    "        # desc = desc.replace(\"  \", \" \") # remove double-spaces after capital letter fix above FIX: don't need bc line above does this automatically?\n",
    "        clean_desc_list.append(desc)\n",
    "    return clean_desc_list\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def tokenize(desc_list): # FIX: how does lemmatization work?\n",
    "    tokens = []\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    tokens = nlp(desc_list)\n",
    "    \n",
    "    lemmatized = []\n",
    "    for token in tokens:\n",
    "        lemmatized.append(token.lemma_)\n",
    "    return tokenized\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def rm_stops(desc_list):\n",
    "    \"\"\" remove stop words and tokenize descriptions for skill parsing  \"\"\"\n",
    "    \n",
    "    clean_desc_list = [] # save all descriptions here\n",
    "    \n",
    "    for desc in desc_list: # loop through each description\n",
    "        clean_desc = [] # save the given description here, to be added to the clean list after\n",
    "        for elem in desc.split(\" \"): # loop through each word in the given description\n",
    "            if elem not in stop: # skip stopwords\n",
    "                clean_desc.append(elem) # save words\n",
    "        stopless_desc = \" \".join(clean_desc) # return all words to a string\n",
    "        clean_desc_list.append(stopless_desc) # add all cleaned descriptions to list\n",
    "        #tokenized = tokenize(clean_desc_list) # tokenize all words\n",
    "    return clean_desc_list#tokenized\n",
    "      \n",
    "\n",
    "\n",
    "def clean_text(desc_list):\n",
    "    \"\"\" Clean all descriptions for use in parsing to find skills \"\"\"\n",
    "    \n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    stop = nlp.Defaults.stop_words # all stop words, for removing stop words from descriptions\n",
    "\n",
    "    desc_list = clean_text(fake_list)\n",
    "    desc_list = rm_stops(fake_list)\n",
    "    \n",
    "    return clean_desc_list\n",
    "\n",
    "\n",
    "\n",
    "def skill_parse(list_):\n",
    "    \"\"\" parse through description for all relevant skills  \"\"\"\n",
    "    return # new column\n",
    "\n",
    "\n",
    "\n",
    "fake_list = [\"WordWordWWWWWWWord\", 'end of bulletNext bullet', 'we Do We want Data AnalystsDO NOT expect anything', ' with an ML Model!']\n",
    "fake_list = clean_text(fake_list)\n",
    "fake_list = rm_stops(fake_list)\n",
    "print(fake_list)\n",
    "#print(clean_text(fake_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764a030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(desc_list):\n",
    "\n",
    "    # SQL -> DF\n",
    "    #df = pd.read_sql_query(\n",
    "    #\"\"\"\n",
    "    #SELECT reviewerName, helpful, reviewText, overall, summary FROM reviews ORDER BY helpful DESC LIMIT 50;\n",
    "    #\"\"\", engine)\n",
    "    \n",
    "    # init vars to use in function\n",
    "    word_list = []\n",
    "    sentiment_ready = []\n",
    "    lemmatized = []\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    stop = nlp.Defaults.stop_words # all stop words, for removing stop words from reviews\n",
    "\n",
    "    # find the sentiment of each review\n",
    "    for desc in desc_list: # for every review\n",
    "        for word in desc_to_split.split(\" \"): # for every word in selected review\n",
    "            if word not in stop:\n",
    "                word_list.append(word)  # add split words from each review into a list of words (word_list)\n",
    "\n",
    "        string_without_stop = \" \".join(word_list) # turn back into a string\n",
    "        tokens = nlp(string_without_stop) # tokenize each review\n",
    "\n",
    "        for token in tokens:\n",
    "            lemmatized.append(token.lemma_) # lemmatize each review\n",
    "        sentiment_ready.append(TextBlob(\" \".join(lemmatized)).sentiment.polarity) #store the sentiment of each review in a list\n",
    "\n",
    "    # compare to overall (overall-sentiment*5) & add to df\n",
    "    sentiment_comparison = []\n",
    "    for index, rows in df.iterrows():\n",
    "        # print(rows['overall'], sentiment_ready[index]) # a test print, to visualize the difference before outputing a sum\n",
    "        sentiment_comparison.append(rows['overall']-sentiment_ready[index]*5) # original review score (out of 5) - new score from NLP analysis of review\n",
    "\n",
    "    # store comparison and new value back into df for later visualization\n",
    "    dict_to_merge = {'sentiment polarity':sentiment_ready, \n",
    "                    'sentiment comparison':sentiment_comparison} # Add all lists to a new (temp) dataframe.\n",
    "\n",
    "    # concatenate dataframes\n",
    "    df2 = pd.DataFrame(dict_to_merge)\n",
    "    df_new = pd.concat([df, df2], axis=1)\n",
    "\n",
    "    # export df to new csv\n",
    "    df_new.to_csv('output/amazon_review_sentiment.csv', index=\"False\")\n",
    "\n",
    "    print('average difference between user\\'s review score (out of 5) vs review sentiment score: ',\n",
    "        mean(sentiment_comparison))\n",
    "    \n",
    "    # df to dict\n",
    "    new_dict = df_new.to_dict(orient=\"records\")\n",
    "    \n",
    "    # add average of sentiment score to top of list returned in API call\n",
    "    new_dict.insert(0, f'average difference between user\\'s review score (out of 5) vs review sentiment score: {mean(sentiment_comparison)}')\n",
    "\n",
    "    return jsonify(new_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706e06ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize description for skill parsing\n",
    "df.insert(10, skills, tokenize(df.description)) # FIX: need to self-reference? df =\n",
    "# FIX # print new list of words\n",
    "skills_list = [] # write a list of relevant skills to keep\n",
    "\n",
    "skill_parse(df.description) # parse through description for all relevant skills\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49d6a93",
   "metadata": {},
   "source": [
    "# Export Data to CSV for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1413d941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('linkedin_jobs_cleaned.csv', index = False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b617f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE FROM A SEPARATE USER'S GITHUB PROJECT, used for selecting job roles\n",
    "# https://github.com/AtefehHezavehei/Linkedin_Scraping_Jobs/blob/main/4-data-title-cleaning.ipynb\n",
    "\n",
    "#TECH\n",
    "\n",
    "#Frontend\n",
    "df.loc[df[\"title\"].str.contains(\"front\", case=False), \"title\"] = \"Frontend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"wordpress\", case=False), \"title\"] = \"Frontend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"php\", case=False), \"title\"] = \"Frontend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"xamarin\", case=False), \"title\"] = \"Frontend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"angular\", case=False), \"title\"] = \"Frontend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"node.js\", case=False), \"title\"] = \"Frontend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"kotlin\", case=False), \"title\"] = \"Frontend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"shopify\", case=False), \"title\"] = \"Frontend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"aem developer\", case=False), \"title\"] = \"Frontend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"golang\", case=False), \"title\"] = \"Frontend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"drupal\", case=False), \"title\"] = \"Frontend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"go developer\", case=False), \"title\"] = \"Frontend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"react\", case=False), \"title\"] = \"Frontend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"ruby\", case=False), \"title\"] = \"Frontend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"swift\", case=False), \"title\"] = \"Frontend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"vue.js\", case=False), \"title\"] = \"Frontend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"rpa developer\", case=False), \"title\"] = \"Frontend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"html\", case=False), \"title\"] = \"Frontend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"devops\", case=False), \"title\"] = \"Frontend_Developer\"\n",
    "\n",
    "#Backend\n",
    "df.loc[df[\"title\"].str.contains(\"back\", case=False), \"title\"] = \"Backend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"nodejs\", case=False), \"title\"] = \"Backend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"magento\", case=False), \"title\"] = \"Backend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"integration\", case=False), \"title\"] = \"Backend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"api developer\", case=False), \"title\"] = \"Backend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"laravel\", case=False), \"title\"] = \"Backend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"liferay\", case=False), \"title\"] = \"Backend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"solidity\", case=False), \"title\"] = \"Backend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"unity\", case=False), \"title\"] = \"Backend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"abap\", case=False), \"title\"] = \"Backend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"apigee\", case=False), \"title\"] = \"Backend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"stack\", case=False), \"title\"] = \"Backend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"web developer\", case=False), \"title\"] = \"Backend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"desarrollador\", case=False), \"title\"] = \"Backend_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"hardware\", case=False), \"title\"] = \"Backend_Developer\"\n",
    "\n",
    "#Data\n",
    "df.loc[df[\"title\"].str.contains(\"data\", case=False), \"title\"] = \"Data_Analytics\"\n",
    "df.loc[df[\"title\"].str.contains(\"datos\", case=False), \"title\"] = \"Data_Analytics\"\n",
    "df.loc[df[\"title\"].str.contains(\"machine\", case=False), \"title\"] = \"Data_Analytics\"\n",
    "df.loc[df[\"title\"].str.contains(\"intelligence\", case=False), \"title\"] = \"Data_Analytics\"\n",
    "df.loc[df[\"title\"].str.contains(\"inteligencia\", case=False), \"title\"] = \"Data_Analytics\"\n",
    "df.loc[df[\"title\"].str.contains(\"tableau\", case=False), \"title\"] = \"Data_Analytics\"\n",
    "df.loc[df[\"title\"].str.contains(\"analyst\", case=False), \"title\"] = \"Data_Analytics\"\n",
    "df.loc[df[\"title\"].str.contains(\"bi engineer\", case=False), \"title\"] = \"Data_Analytics\"\n",
    "df.loc[df[\"title\"].str.contains(\"analysis\", case=False), \"title\"] = \"Data_Analytics\"\n",
    "df.loc[df[\"title\"].str.contains(\"analytics\", case=False), \"title\"] = \"Data_Analytics\"\n",
    "df.loc[df[\"title\"].str.contains(\"business consultant\", case=False), \"title\"] = \"Data_Analytics\"\n",
    "df.loc[df[\"title\"].str.contains(\"analista\", case=False), \"title\"] = \"Data_Analytics\"\n",
    "df.loc[df[\"title\"].str.contains(\"power bi\", case=False), \"title\"] = \"Data_Analytics\"\n",
    "df.loc[df[\"title\"].str.contains(\"scraping\", case=False), \"title\"] = \"Data_Analytics\"\n",
    "df.loc[df[\"title\"].str.contains(\"bi developer\", case=False), \"title\"] = \"Data_Analytics\"\n",
    "df.loc[df[\"title\"].str.contains(\"analytical\", case=False), \"title\"] = \"Data_Analytics\"\n",
    " \n",
    "\n",
    "#Security\n",
    "df.loc[df[\"title\"].str.contains(\"ciberseguridad\", case=False), \"title\"] = \"Cybersecurity\"\n",
    "df.loc[df[\"title\"].str.contains(\"cybersecurity\", case=False), \"title\"] = \"Cybersecurity\"\n",
    "df.loc[df[\"title\"].str.contains(\"cyber\", case=False), \"title\"] = \"Cybersecurity\"\n",
    "df.loc[df[\"title\"].str.contains(\"security\", case=False), \"title\"] = \"Cybersecurity\"\n",
    "df.loc[df[\"title\"].str.contains(\"seguridad\", case=False), \"title\"] = \"Cybersecurity\"\n",
    "df.loc[df[\"title\"].str.contains(\"virtualización\", case=False), \"title\"] = \"Cybersecurity\"\n",
    "\n",
    "\n",
    "\n",
    "#Cloud\n",
    "df.loc[df[\"title\"].str.contains(\"cloud\", case=False), \"title\"] = \"Cloud_Expert\"\n",
    "df.loc[df[\"title\"].str.contains(\"azure\", case=False), \"title\"] = \"Cloud_Expert\"\n",
    "df.loc[df[\"title\"].str.contains(\"microsoft\", case=False), \"title\"] = \"Cloud_Expert\"\n",
    "df.loc[df[\"title\"].str.contains(\"aws\", case=False), \"title\"] = \"Cloud_Expert\"\n",
    "df.loc[df[\"title\"].str.contains(\"google\", case=False), \"title\"] = \"Cloud_Expert\"\n",
    "df.loc[df[\"title\"].str.contains(\"Salesforce\", case=False), \"title\"] = \"Cloud_Expert\"\n",
    "df.loc[df[\"title\"].str.contains(\"sales force consultant\", case=False), \"title\"] = \"Cloud_Expert\"\n",
    "df.loc[df[\"title\"].str.contains(\"crm\", case=False), \"title\"] = \"Cloud_Expert\"\n",
    "\n",
    "\n",
    "#UX/UI\n",
    "df.loc[df[\"title\"].str.contains(\"ux/ui\", case=False), \"title\"] = \"UX/UI_Designer\"\n",
    "df.loc[df[\"title\"].str.contains(\"designer\", case=False), \"title\"] = \"UX/UI_Designer\"\n",
    "df.loc[df[\"title\"].str.contains(\"diseñador\", case=False), \"title\"] = \"UX/UI_Designer\"\n",
    "df.loc[df[\"title\"].str.contains(\"ui ux web design\", case=False), \"title\"] = \"UX/UI_Designer\"\n",
    "df.loc[df[\"title\"].str.contains(\"diseño\", case=False), \"title\"] = \"UX/UI_Designer\"\n",
    "df.loc[df[\"title\"].str.contains(\"ui developer\", case=False), \"title\"] = \"UX/UI_Designer\"\n",
    "df.loc[df[\"title\"].str.contains(\"ecommerce\", case=False), \"title\"] = \"UX/UI_Designer\"\n",
    "df.loc[df[\"title\"].str.contains(\"e-commerce\", case=False), \"title\"] = \"UX/UI_Designer\"\n",
    "df.loc[df[\"title\"].str.contains(\"comercio\", case=False), \"title\"] = \"UX/UI_Designer\"\n",
    " \n",
    "#System Admin\n",
    "df.loc[df[\"title\"].str.contains(\"arquitecto\", case=False), \"title\"] = \"System_Admin\"\n",
    "df.loc[df[\"title\"].str.contains(\"administrator\", case=False), \"title\"] = \"System_Admin\"\n",
    "df.loc[df[\"title\"].str.contains(\"database\", case=False), \"title\"] = \"System_Admin\"\n",
    "df.loc[df[\"title\"].str.contains(\"system engineer\", case=False), \"title\"] = \"System_Admin\"\n",
    "df.loc[df[\"title\"].str.contains(\"sistemas\", case=False), \"title\"] = \"System_Admin\"\n",
    "df.loc[df[\"title\"].str.contains(\"systems\", case=False), \"title\"] = \"System_Admin\"\n",
    "df.loc[df[\"title\"].str.contains(\"system\", case=False), \"title\"] = \"System_Admin\"\n",
    "df.loc[df[\"title\"].str.contains(\"linux\", case=False), \"title\"] = \"System_Admin\"\n",
    "df.loc[df[\"title\"].str.contains(\"windows\", case=False), \"title\"] = \"System_Admin\"\n",
    "df.loc[df[\"title\"].str.contains(\"office\", case=False), \"title\"] = \"System_Admin\"\n",
    "df.loc[df[\"title\"].str.contains(\"platform\", case=False), \"title\"] = \"System_Admin\"\n",
    "df.loc[df[\"title\"].str.contains(\"platforma\", case=False), \"title\"] = \"System_Admin\"\n",
    "\n",
    "\n",
    "#SW_App Developer\n",
    "df.loc[df[\"title\"].str.contains(\"java\", case=False), \"title\"] = \"SW_APP_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"software\", case=False), \"title\"] = \"SW_APP_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"python\", case=False), \"title\"] = \"SW_APP_Developer\" \n",
    "df.loc[df[\"title\"].str.contains(\".net\", case=False), \"title\"] = \"SW_APP_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"net\", case=False), \"title\"] = \"SW_APP_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"programador\", case=False), \"title\"] = \"SW_APP_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"automation\", case=False), \"title\"] = \"SW_APP_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"automatización\", case=False), \"title\"] = \"SW_APP_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"developer senior\", case=False), \"title\"] = \"SW_APP_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"junior developer\", case=False), \"title\"] = \"SW_APP_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"sw\", case=False), \"title\"] = \"SW_APP_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"microservices\", case=False), \"title\"] = \"SW_APP_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"android\", case=False), \"title\"] = \"SW_APP_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"aplicaciones\", case=False), \"title\"] = \"SW_APP_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"ios developer\", case=False), \"title\"] = \"SW_APP_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"application\", case=False), \"title\"] = \"SW_APP_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"mobile\", case=False), \"title\"] = \"SW_APP_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"app\", case=False), \"title\"] = \"SW_APP_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"ios engineer\", case=False), \"title\"] = \"SW_APP_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"flutter\", case=False), \"title\"] = \"SW_APP_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"movilidad\", case=False), \"title\"] = \"SW_APP_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"smart\", case=False), \"title\"] = \"SW_APP_Developer\"\n",
    "df.loc[df[\"title\"].str.contains(\"smartphone\", case=False), \"title\"] = \"SW_APP_Developer\"\n",
    "\n",
    "\n",
    "#Network_Expert\n",
    "df.loc[df[\"title\"].str.contains(\"network\", case=False), \"title\"] = \"Network_Expert\"\n",
    "df.loc[df[\"title\"].str.contains(\"telecomunicaciones\", case=False), \"title\"] = \"Network_Expert\"\n",
    "df.loc[df[\"title\"].str.contains(\"telecommunications\", case=False), \"title\"] = \"Network_Expert\"\n",
    "df.loc[df[\"title\"].str.contains(\"redes\", case=False), \"title\"] = \"Network_Expert\"\n",
    "\n",
    "\n",
    "#QA Engineer\n",
    "df.loc[df[\"title\"].str.contains(\"qa\", case=False), \"title\"] = \"QA_Engineer\"\n",
    "df.loc[df[\"title\"].str.contains(\"test\", case=False), \"title\"] = \"QA_Engineer\"\n",
    "df.loc[df[\"title\"].str.contains(\"quality assurance\", case=False), \"title\"] = \"QA_Engineer\"\n",
    "df.loc[df[\"title\"].str.contains(\"software quality\", case=False), \"title\"] = \"QA_Engineer\"\n",
    "df.loc[df[\"title\"].str.contains(\"tester\", case=False), \"title\"] = \"QA_Engineer\"\n",
    "\n",
    "\n",
    "#IT Support\n",
    "df.loc[df[\"title\"].str.contains(\"it manager\", case=False), \"title\"] = \"IT_Support\"\n",
    "df.loc[df[\"title\"].str.contains(\"engineering\", case=False), \"title\"] = \"IT_Support\"\n",
    "df.loc[df[\"title\"].str.contains(\"it support\", case=False), \"title\"] = \"IT_Support\"\n",
    "df.loc[df[\"title\"].str.contains(\"it operational\", case=False), \"title\"] = \"IT_Support\"\n",
    "df.loc[df[\"title\"].str.contains(\"technical support\", case=False), \"title\"] = \"IT_Support\"\n",
    "df.loc[df[\"title\"].str.contains(\"internal\", case=False), \"title\"] = \"IT_Support\"\n",
    "df.loc[df[\"title\"].str.contains(\"informatico\", case=False), \"title\"] = \"IT_Support\"\n",
    "df.loc[df[\"title\"].str.contains(\"informática\", case=False), \"title\"] = \"IT_Support\"\n",
    "df.loc[df[\"title\"].str.contains(\"informático\", case=False), \"title\"] = \"IT_Support\"\n",
    "df.loc[df[\"title\"].str.contains(\"sharepoint\", case=False), \"title\"] = \"IT_Support\"\n",
    "df.loc[df[\"title\"].str.contains(\"365\", case=False), \"title\"] = \"IT_Support\" \n",
    "\n",
    "#Solution_Architect\n",
    "df.loc[df[\"title\"].str.contains(\"solution\", case=False), \"title\"] = \"Solution_Architect\"\n",
    "df.loc[df[\"title\"].str.contains(\"solutions\", case=False), \"title\"] = \"Solution_Architect\"\n",
    "df.loc[df[\"title\"].str.contains(\"architect\", case=False), \"title\"] = \"Solution_Architect\"\n",
    "df.loc[df[\"title\"].str.contains(\"architecture\", case=False), \"title\"] = \"Solution_Architect\"\n",
    "df.loc[df[\"title\"].str.contains(\"blockchain\", case=False), \"title\"] = \"Solution_Architect\"\n",
    "df.loc[df[\"title\"].str.contains(\"tech lead\", case=False), \"title\"] = \"Solution_Architect\"\n",
    "df.loc[df[\"title\"].str.contains(\"integración\", case=False), \"title\"] = \"Solution_Architect\"\n",
    "df.loc[df[\"title\"].str.contains(\"integrador\", case=False), \"title\"] = \"Solution_Architect\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
